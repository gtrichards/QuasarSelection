{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final SpIES High-z Quasar Selection\n",
    "\n",
    "Notebook performing selection of $3.5<z<5$ quasars from SDSS+SpIES data.\n",
    "\n",
    "Largely the same as `SpIESHighzQuasars` notebook except using the algoirthm(s) from\n",
    "`SpIESHighzCandidateSelection2`.  See notes below for creating a version of the\n",
    "test set that includes i-band mag and extinctu.  (This wasn't easy.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the training data, then instantiate and train the algorithm; see [https://github.com/gtrichards/QuasarSelection/blob/master/SpIESHighzCandidateSelection2.ipynb](https://github.com/gtrichards/QuasarSelection/blob/master/SpIESHighzCandidateSelection2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gtr/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = Table.read('GTR-ADM-QSO-ir-testhighz_findbw_lup_2016_starclean.fits')\n",
    "\n",
    "# X is in the format need for all of the sklearn tools, it just has the colors\n",
    "# X = np.vstack([ data['ug'], data['gr'], data['ri'], data['iz'], data['zs1'], data['s1s2'], data['imag'], data['extinctu']]).T\n",
    "# Don't use imag and extinctu since they don't contribute much to the accuracy and they add a lot to the data volume.\n",
    "X = np.vstack([ data['ug'], data['gr'], data['ri'], data['iz'], data['zs1'], data['s1s2'] ]).T\n",
    "y = np.array(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For algorithms that need scaled data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)  # Use the full training set now\n",
    "XStrain = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(XStrain,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.5, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bag = BaggingClassifier(KNeighborsClassifier(n_neighbors=7), max_samples=0.5, max_features=1.0, random_state=42)\n",
    "bag.fit(XStrain, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, load the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "Test set data set was made as follows (see 18 April 2016 README entry):\n",
    "   \n",
    "    maketest_2016.py\n",
    "\n",
    "    Output is:\n",
    "    classifiers_out = open('GTR-ADM-QSO-ir_classifiers_good_test_2016.dat','w') \n",
    "    others_out= open('GTR-ADM-QSO-ir_others_good_test_2016.dat','w')\n",
    "    czr_out = open('GTR-ADM-QSO-ir_photoz_in7_good_test_2016.dat','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really need the first two files combined (so that we have both RA/Dec and colors in one place).\n",
    "\n",
    "But couldn't merge them with TOPCAT or STILTS.  So had to break them into 3 pieces (with TOPCAT),\n",
    "then used `combine_test_files_STILTS.py` to merge them together (just changing the input/output file names by hand).  \n",
    "\n",
    "Actually ran this on dirac so that I'd have more memory than on quasar.  Copied the output files back to quasar and merged them together with TOPCAT.\n",
    "\n",
    "So<br>\n",
    "`GTR-ADM-QSO-ir_others_good_test_2016a.dat` + `GTR-ADM-QSO-ir_classifiers_good_test_2016a.dat`<br>\n",
    "gives<br>\n",
    "`GTR-ADM-QSO-ir_good_test_2016a.dat`<br>\n",
    "(and so on for \"b\" and \"c\").\n",
    "\n",
    "Then<br>\n",
    "`GTR-ADM-QSO-ir_good_test_2016a.dat` + `GTR-ADM-QSO-ir_good_test_2016b.dat` + `GTR-ADM-QSO-ir_good_test_2016c.dat`<br>\n",
    "gives<br>\n",
    "`GTR-ADM-QSO-ir_good_test_2016.dat`<br>\n",
    "and similarly for the fits output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I wanted to use the `imag` `and extinctu`, then I also had to make a version of the test file with `combine_test_files_STILTSn.py` (on quasar).  This was fairly involved because of memory issues.  The new output file is `GTR-ADM-QSO-ir_good_test_2016n.dat`.  In the end, I ended up not using that and this is more of an exploration of SVM and bagging as alternatives to RF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in the test file and convert it to an appropriate array format for sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data2 = Table.read('GTR-ADM-QSO-ir_good_test_2016n.fits')\n",
    "data2 = Table.read('GTR-ADM-QSO-ir_good_test_2016.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ra', 'dec', 'iflux', 'morph', 'knownqso', 'extinctu', 'ug', 'gr', 'ri', 'iz', 'zs1', 's1s2', 'i', 's2', 'ierr', 's2err']\n"
     ]
    }
   ],
   "source": [
    "print data2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some problems with `GTR-ADM-QSO-ir_good_test_2016n.fits` because it thought that there were blank entries among the attributes.  There actually weren't (as far as I could tell), but I found that I could use `filled` to fix the problem.  However, that just caused problems later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not sure why I need to do this because there don't appear to be any unfilled columns\n",
    "# but the code segment below won't run without it.\n",
    "# Only need to do for the file with imag and extinctu\n",
    "# data2 = data2.filled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Taking too long to do all the objects, so just do Stripe 82, which is all that we really care about anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ramask = ( ( (data2['ra']>=300.0) & (data2['ra']<=360.0) ) | ( (data2['ra']>=0.0) & (data2['ra']<=60.0) ) )\n",
    "decmask = ((data2['dec']>=-1.5) & (data2['dec']<=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataS82 = data2[ramask & decmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2029149\n"
     ]
    }
   ],
   "source": [
    "print len(dataS82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Xtest = np.vstack([dataS82['ug'], dataS82['gr'], dataS82['ri'], dataS82['iz'], dataS82['zs1'], dataS82[]'s1s2'], dataS82['i'], data2['extinctu']]).T\n",
    "Xtest = np.vstack([dataS82['ug'], dataS82['gr'], dataS82['ri'], dataS82['iz'], dataS82['zs1'], dataS82['s1s2'] ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XStest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasar Candidates\n",
    "Finally, do the classification and output the test file, including the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask import compute, delayed\n",
    "\n",
    "def processSVM(Xin):\n",
    "    return svm.predict(Xin)\n",
    "\n",
    "# Create dask objects\n",
    "# Reshape is necessary because the format of x as drawm from Xtest \n",
    "# is not what sklearn wants.\n",
    "dobjsSVM = [delayed(processSVM)(x.reshape(1,-1)) for x in XStest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.threaded\n",
    "ypredSVM = compute(*dobjsSVM, get=dask.threaded.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypredSVM = np.array(ypredSVM).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask import compute, delayed\n",
    "\n",
    "def processBAG(Xin):\n",
    "    return bag.predict(Xin)\n",
    "\n",
    "# Create dask objects\n",
    "# Reshape is necessary because the format of x as drawm from Xtest \n",
    "# is not what sklearn wants.\n",
    "dobjsBAG = [delayed(processBAG)(x.reshape(1,-1)) for x in XStest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.threaded\n",
    "ypredBAG = compute(*dobjsBAG, get=dask.threaded.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypredBAG = np.array(ypredBAG).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write results to output file.  Didn't do bagging b/c takes too long.  See `SpIESHighzQuasarsS82all.py` which I ran on dirac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataS82['ypredSVM'] = ypredSVM\n",
    "dataS82['ypredBAG'] = ypredBAG\n",
    "#dataS82.write('GTR-ADM-QSO-ir_good_test_2016_Stripe82svm.fits', format='fits')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
