{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final SpIES High-z Quasar Selection\n",
    "\n",
    "Notebook performing selection of $3.5<z<5$ quasars from SDSS+SpIES data.\n",
    "\n",
    "First load the training data, then instantiate and train the algorithm; see [https://github.com/gtrichards/QuasarSelection/blob/master/SpIESHighzCandidateSelection.ipynb](https://github.com/gtrichards/QuasarSelection/blob/master/SpIESHighzCandidateSelection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gtr/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = Table.read('GTR-ADM-QSO-ir-testhighz_findbw_lup_2016_starclean.fits')\n",
    "\n",
    "# X is in the format need for all of the sklearn tools, it just has the colors\n",
    "X = np.vstack([ data['ug'], data['gr'], data['ri'], data['iz'], data['zs1'], data['s1s2']]).T\n",
    "y = np.array(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=15, min_samples_split=2, n_jobs=-1, random_state=42)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, load the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "Test set data set was made as follows (see 18 April 2016 README entry):\n",
    "   \n",
    "    maketest_2016.py\n",
    "\n",
    "    Output is:\n",
    "    classifiers_out = open('GTR-ADM-QSO-ir_classifiers_good_test_2016.dat','w') \n",
    "    others_out= open('GTR-ADM-QSO-ir_others_good_test_2016.dat','w')\n",
    "    czr_out = open('GTR-ADM-QSO-ir_photoz_in7_good_test_2016.dat','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really need the first two files combined (so that we have both RA/Dec and colors in one place).\n",
    "\n",
    "But couldn't merge them with TOPCAT or STILTS.  So had to break them into 3 pieces (with TOPCAT),\n",
    "then used `combine_test_files_STILTS.py` to merge them together (just changing the input/output file names by hand).  \n",
    "\n",
    "Actually ran this on dirac so that I'd have more memory than on quasar.  Copied the output files back to quasar and merged them together with TOPCAT.\n",
    "\n",
    "So<br>\n",
    "`GTR-ADM-QSO-ir_others_good_test_2016a.dat` + `GTR-ADM-QSO-ir_classifiers_good_test_2016a.dat`<br>\n",
    "gives<br>\n",
    "`GTR-ADM-QSO-ir_good_test_2016a.dat`<br>\n",
    "(and so on for \"b\" and \"c\").\n",
    "\n",
    "Then<br>\n",
    "`GTR-ADM-QSO-ir_good_test_2016a.dat` + `GTR-ADM-QSO-ir_good_test_2016b.dat` + `GTR-ADM-QSO-ir_good_test_2016c.dat`<br>\n",
    "gives<br>\n",
    "`GTR-ADM-QSO-ir_good_test_2016.dat`\n",
    "\n",
    "N.B.  Had to delete the intermediate files from quasar to save disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GTR: Re-did this with `combine_test_files_STILTSn.py` (on quasar) since I wanted to include the i-band and ch2 magnitudes.  The output file is still `GTR-ADM-QSO-ir_good_test_2016.dat`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in the test file and convert it to an appropriate array format for sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50939704 [[  3.81193849e-02   3.65796465e-01   5.31836570e-02  -4.89434865e-02\n",
      "    6.28884801e-01   6.24938477e-01]\n",
      " [  5.08303480e-01   1.11420093e-01   8.65531714e-02   1.03706865e-01\n",
      "    4.21802021e-01   3.36181068e-01]\n",
      " [  1.65061871e+00   1.13939853e-01   1.54225782e-01   4.41376234e-01\n",
      "    4.62311618e-01   4.68052444e-01]\n",
      " [  3.68773847e-01   2.59072437e-01   1.81469411e-01   1.44563753e-02\n",
      "    7.14639858e-01   7.00231807e-01]\n",
      " [ -1.32032589e-02   1.96339791e-01   7.44004894e-02   5.95867945e-04\n",
      "    1.46086353e+00   3.08763164e-01]]\n"
     ]
    }
   ],
   "source": [
    "data2 = Table.read('GTR-ADM-QSO-ir_good_test_2016.fits')\n",
    "#data2 = Table.read('GTR-ADM-QSO-ir_classifiers_good_test_2016.fits')\n",
    "#data2 = Table.read('gtr-adm-qso-ir_photoz_in7_good_test_2016.fits')\n",
    "\n",
    "Xtest = np.vstack([ data2['ug'], data2['gr'], data2['ri'], data2['iz'], data2['zs1'], data2['s1s2']]).T\n",
    "\n",
    "print len(Xtest),Xtest[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasar Candidates\n",
    "Finally, do the classification and output the test file, including the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "50939704\n"
     ]
    }
   ],
   "source": [
    "print ypred[:5]\n",
    "print len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2['ypred'] = ypred\n",
    "data2.write('GTR-ADM-QSO-ir_good_test_2016_out.fits', format='fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives about 27,000 candidates in all and about 3000 on Stripe 82.\n",
    "\n",
    "You can get the output file from\n",
    "[http://www.physics.drexel.edu/~gtr/outgoing/spies/GTR-ADM-QSO-ir_good_test_2016_out.fits.bz2](http://www.physics.drexel.edu/~gtr/outgoing/spies/GTR-ADM-QSO-ir_good_test_2016_out.fits.bz2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27225\n"
     ]
    }
   ],
   "source": [
    "mask = (data2['ypred']==0)\n",
    "quasars = data2[mask]\n",
    "print len(quasars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main test set classification ends here.  But see below for some experimenting with bagging.\n",
    "\n",
    "Also, see<br>\n",
    "```SpIESHighzQuasarsS82all.py```<br>\n",
    "for some stand-alone code that classifies Stripe 82 candidates by RF, SVM and bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging classifier\n",
    "\n",
    "If we want to try bagging instead, here is how we'd do that.  But this takes a really long time unless we restrict ourselves to just Stripe 82.  We'll use `dask` to schedule the processes, otherwise it kills the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)  # Use the full training set now\n",
    "XS = scaler.transform(X)\n",
    "XStest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bag = BaggingClassifier(KNeighborsClassifier(n_neighbors=5), max_samples=0.5, max_features=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.5, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.fit(XS, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask import compute, delayed\n",
    "\n",
    "def processBAG(Xin):\n",
    "    return bag.predict(Xin)\n",
    "\n",
    "# Create dask objects\n",
    "# Reshape is necessary because the format of x as drawm from Xtest \n",
    "# is not what sklearn wants.\n",
    "dobjsBAG = [delayed(processBAG)(x.reshape(1,-1)) for x in XStest]\n",
    "#print dobjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if we can even handle the first million objects, let alone the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Delayed('processBAG-6d7253d1-9dd0-4a7f-b328-d18caa8cf2b8'), Delayed('processBAG-f1987c0b-131a-4686-882a-0bd7f8e38f53'), Delayed('processBAG-030c344d-88f9-4600-b181-924342a29a90'), Delayed('processBAG-79eecb00-b136-4983-b21e-3f8f54cead4f'), Delayed('processBAG-ece8d4ea-41a5-4ade-ab9c-d5078f8df356')]\n"
     ]
    }
   ],
   "source": [
    "print dobjsBAG[:5]\n",
    "dobjsBAG1 = dobjsBAG[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask.threaded\n",
    "ypredBAG1 = compute(*dobjsBAG1, get=dask.threaded.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypredBAG1 = np.array(ypredBAG1).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print ypredBAG1[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IFF we could get this to work, then we'd produce output as follows.  But this always crashes.  Tried running on dirac and it crashes there too.  So, had to concentrate on Stripe 82.  See ```SpIESHighzQuasarsS82all.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2['ypred'] = ypredBAG\n",
    "data2.write('GTR-ADM-QSO-ir_good_test_2016_out_bag.fits', format='fits')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
